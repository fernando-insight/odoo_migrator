{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hermitage I5 migration notebook\n",
    "\n",
    "This notebook app will run the ETL process to migrate Heremitage's I5 to a new Odoo 15 system.\n",
    "It will read csv/tsv files from the input_csv_files, make the necessary transformations to make it importable in Odoo 15 and then load the data it into Hermitage's new Odoo 15 instance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "- pandas: to make transformations on the data\n",
    "- Models' migration config\n",
    "- Import function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas\n",
    "\n",
    "from models_migration_config import models_migration_config\n",
    "\n",
    "from import_functions import import_data, import_ignored_fields\n",
    "\n",
    "INPUT_CSV_FILES_PATH = 'input_csv_files/'\n",
    "GENERATED_CSV_FILES_PATH = 'generated_csv_files/'\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform Vendors from I5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vendors_file_path = f'{INPUT_CSV_FILES_PATH}APMASTER - Vendors.tsv'\n",
    "vendors_dataframe = pandas.read_csv(vendors_file_path, sep='\\t')\n",
    "vendors_dataframe = vendors_dataframe.fillna('')\n",
    "# AMVEND\tAMNAME\tAMADR1\tAMADR2\tAMADR3\tAMTELE\tAMFRGT\tactual_term\n",
    "# 1\tBROAN MFG OR EDN\t4641 PAYSPHERE CIRCLE\tCHICAGO,IL 60674         \t\t8778470145\t1250\t2% 10TH PROX\n",
    "# 172\tHUNTER FAN COMPANY\tP O BOX 19773\t\tPALATINE IL 60055-9773\t9017441200\t1000\t1% 20TH\n",
    "# 10003\tLEDVANCE OR IMARK\tP O BOX 72524\t(OSRAM)\tCLEVELAND OH 44192\t8002555042\t1000\t2% 90Days\n",
    "# 10004\tADVANCE TRANSFORMER CO\tP O BOX 100332\tATLANTA GA  30384\t\t0\t750\t2% 10TH PROX\n",
    "# 10005\tLUTRON ELECTRONICS CO INC\tP O BOX 644396\t\tPITTSBURGH, PA 15264-4396\t8005239466\t500\t1%10TH PROX\n",
    "\n",
    "col_names = ['AMVEND', 'AMNAME', 'AMADR1', 'AMADR2', 'AMADR3', 'AMTELE', 'AMFRGT', 'actual_term']\n",
    "for col_name in col_names:\n",
    "    vendors_dataframe[col_name] = vendors_dataframe[col_name].astype(str)\n",
    "    vendors_dataframe[col_name] = vendors_dataframe[col_name].str.strip()\n",
    "\n",
    "# Move AMADR1 column to the end for better visibility\n",
    "vendors_dataframe = vendors_dataframe[['AMVEND', 'AMNAME', 'AMADR2', 'AMADR3', 'AMTELE', 'AMFRGT', 'actual_term', 'AMADR1']]\n",
    "vendors_dataframe.rename(columns={'AMADR1': 'street'}, inplace=True)\n",
    "\n",
    "vendors_dataframe['street2'] = ''\n",
    "vendors_dataframe['city'] = ''\n",
    "vendors_dataframe['state_code'] = ''\n",
    "vendors_dataframe['zip'] = ''\n",
    "\n",
    "def is_zip(zip_code : str) -> bool:\n",
    "    \"\"\"\n",
    "    >>> is_zip('6067')\n",
    "    True\n",
    "    >>> is_zip('60674')\n",
    "    True\n",
    "    >>> is_zip('60674-1234')\n",
    "    True\n",
    "    \"\"\"\n",
    "    return bool(re.match(r'^\\d{5}(-\\d{4})?$', zip_code)) or bool(re.match(r'^\\d{4}', zip_code))\n",
    "\n",
    "us_states = {\n",
    "    'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY',\n",
    "    'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY',\n",
    "    'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY'\n",
    "}\n",
    "\n",
    "def is_a_state(state : str) -> bool:\n",
    "    return state in us_states\n",
    "\n",
    "def clean_address_field(address_field: str) -> str:\n",
    "    address_field = address_field.strip()\n",
    "    address_field = re.sub(r'\\s+', ' ', address_field)\n",
    "    address_field = address_field.replace(',', ' ')\n",
    "    return address_field\n",
    "\n",
    "\n",
    "for row_index, row in vendors_dataframe.iterrows():\n",
    "    row_address2 = row.AMADR2 or ''\n",
    "    row_address2 = clean_address_field(row_address2)\n",
    "    row_address3 = row.AMADR3 or ''\n",
    "    row_address3 = clean_address_field(row_address3)\n",
    "\n",
    "    if row_address3:\n",
    "        row.street2 = row_address2\n",
    "        city_state_zip = row_address3\n",
    "    else:\n",
    "        city_state_zip = row_address2\n",
    "    if city_state_zip:\n",
    "        city_state_zip_splitted = city_state_zip.split(' ')[::-1]\n",
    "\n",
    "        for i, address_field in enumerate(city_state_zip_splitted):\n",
    "            if is_zip(address_field):\n",
    "                row.zip = address_field.strip()\n",
    "            elif is_a_state(address_field):\n",
    "                row.state_code = address_field.strip()\n",
    "            else:\n",
    "                row.city = ' '.join(city_state_zip_splitted[i:][::-1]).strip()\n",
    "                break\n",
    "        if not row.zip or not row.state_code or not row.city and row.street2:\n",
    "            city_state_zip_splitted = row.street2.split(' ')[::-1]\n",
    "            for i, address_field in enumerate(city_state_zip_splitted):\n",
    "                if not row.zip and is_zip(address_field):\n",
    "                    row.zip = address_field.strip()\n",
    "                elif not row.state_code and is_a_state(address_field):\n",
    "                    row.state_code = address_field.strip()\n",
    "                elif not row.city:\n",
    "                    row.city = ' '.join(city_state_zip_splitted[i:][::-1]).strip()\n",
    "                    break\n",
    "\n",
    "states_dataframe = pandas.read_csv(f'{INPUT_CSV_FILES_PATH}state_codes.csv')\n",
    "# Merge with states to get the state and country external id\n",
    "vendors_dataframe = pandas.merge(vendors_dataframe, states_dataframe, on='state_code', how='left')\n",
    "\n",
    "# Merge with the payment terms to get the payment term external id\n",
    "payment_terms_dataframe = pandas.read_csv(f'{INPUT_CSV_FILES_PATH}account.payment.term.csv')\n",
    "payment_terms_dataframe.rename(columns={'name': 'actual_term', 'id': 'property_supplier_payment_term_id/id'}, inplace=True)\n",
    "merge_payment_terms_dataframe = payment_terms_dataframe[['actual_term', 'property_supplier_payment_term_id/id']]\n",
    "\n",
    "vendors_dataframe = pandas.merge(vendors_dataframe, merge_payment_terms_dataframe, on='actual_term', how='left')\n",
    "# remove unneeded columns\n",
    "vendors_dataframe.drop(columns=['AMADR2', 'AMADR3', 'AMFRGT', 'actual_term', 'state_code'], inplace=True)\n",
    "# rename columns to match the odoo model\n",
    "vendors_dataframe.rename(columns={\n",
    "    'AMVEND': 'vendor_account_number',\n",
    "    'AMNAME': 'name',\n",
    "    'AMTELE': 'phone'\n",
    "}, inplace=True)\n",
    "\n",
    "vendors_dataframe.insert(0, 'supplier_rank', 1)\n",
    "# add Vendor tag\n",
    "vendors_dataframe.insert(0, 'category_id/id', '__export__.res_partner_category_56_7fafda33')\n",
    "# add id column populated with ids generated from 'i5_migration.res.partner.vendors_{row_index}'\n",
    "vendors_dataframe.insert(0, 'id', [f'i5_migration.res.partner.vendor_{row_index}' for row_index in range(1, 1 + len(vendors_dataframe))])\n",
    "\n",
    "vendors_dataframe.to_csv(f'{GENERATED_CSV_FILES_PATH}i5.vendors.csv', index=False, sep=',')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load vendors (res.partner)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_data(file_csv='i5.vendors.csv', model_name='res.partner')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform locations from I5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = 'stock.location'\n",
    "\n",
    "company_id = 'base.main_company'\n",
    "\n",
    "locations_dataframe = pandas.read_csv(f'{INPUT_CSV_FILES_PATH}RFLOCATE.tsv', sep='\\t')\n",
    "# locations_dataframe = locations_dataframe.fillna('')\n",
    "# #cast all columns to str\n",
    "locations_dataframe = locations_dataframe.astype(str)\n",
    "# #Trimm spaces\n",
    "locations_dataframe = locations_dataframe.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "#Format of i5 locations file\n",
    "# id  name\n",
    "# 9010101\tINVENTORY LOCATION  \n",
    "# 9060101\t                    \n",
    "# 9200101\tCOMM WHSE           \n",
    "# 9270101\t                    \n",
    "# 9270201\t                    \n",
    "# 9270301\t                    \n",
    "# 9270401\t                    \n",
    "# 9270501\t                    \n",
    "# 9270601\t                    \n",
    "# 9270701\t                    \n",
    "\n",
    "# Main stock.location id: stock.stock_location_stock\n",
    "\n",
    "# Columns needed for Odoo's locations dataframe\n",
    "# id,name,usage,company_id/id,parent_id/id,temporary_parent_id\n",
    "\n",
    "# The locations hierarchy is as follows:\n",
    "# 1 - stock.stock_location_stock --> i5 Value: 9\n",
    "# 2 - Aisle\n",
    "# 3 - Section(venv) fernando@fernando-Z370-AORUS-Ultra-Gaming:/media/fernando/Shared/hermitage$ \n",
    "# 4 - INVENTORY LOCATION (if it has a name the shelf location is called by the name, otherwise it is called by the id)\n",
    "# Would generate the following locations:\n",
    "# i5_migration.stock.location_aisle_01,Aisle 01,internal,base.main_company,stock.stock_location_stock,stock.stock_location_stock\n",
    "# i5_migration.stock.location_section_01_01,Section 01,internal,base.main_company,i5_migration.stock.location_aisle_01,stock.stock_location_stock\n",
    "# i5_migration.stock.location_shelf_01_01_01,Shelf 01 (INVENTORY LOCATION),internal,base.main_company,i5_migration.stock.location_section_01_01,stock.stock_location_stock\n",
    "\n",
    "# Example 2: for location 9060101\n",
    "# 1 - stock.stock_location_stock (already created)\n",
    "# 2 - Aisle 06\n",
    "# 3 - Section 01\n",
    "# 4 - Shelf 01\n",
    "# Would generate the following locations:\n",
    "# i5_migration.stock.location_aisle_06,Aisle 06,internal,base.main_company,stock.stock_location_stock,stock.stock_location_stock\n",
    "# i5_migration.stock.location_section_06_01,Section 01,internal,base.main_company,i5_migration.stock.location_aisle_06,stock.stock_location_stock\n",
    "# i5_migration.stock.location_shelf_06_01_01,Shelf 01,internal,base.main_company,i5_migration.stock.location_section_06_01,stock.stock_location_stock\n",
    "\n",
    "\n",
    "transformation_result_dataframe = pandas.DataFrame(columns=['id', 'name', 'usage', 'company_id/id', 'location_id/id', 'temporary_parent_id'])\n",
    "aisles_ids = set()\n",
    "section_ids = set()\n",
    "shelf_ids = set()\n",
    "for location in locations_dataframe.iterrows():\n",
    "    ## Aisle ##\n",
    "    aisle_number = str(location[1].id)[1:3]\n",
    "    aisle_id = f'i5_migration.stock.location_aisle_{aisle_number}'\n",
    "    if aisle_id not in aisles_ids:\n",
    "        aisles_ids.add(aisle_id)\n",
    "        transformation_result_dataframe = transformation_result_dataframe.append({\n",
    "            'id': f'i5_migration.stock.location_aisle_{aisle_number}',\n",
    "            'name': f'Aisle {aisle_number}',\n",
    "            'usage': 'internal',\n",
    "            'company_id/id': 'base.main_company',\n",
    "            'location_id/id': 'stock.stock_location_stock',\n",
    "            'temporary_parent_id': 'stock.stock_location_stock'\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    ## Section ##\n",
    "    section_number = str(location[1].id)[3:5]\n",
    "    section_id = f'i5_migration.stock.location_section_{aisle_number}_{section_number}'\n",
    "    if section_id not in section_ids:\n",
    "        section_ids.add(section_id)\n",
    "        transformation_result_dataframe = transformation_result_dataframe.append({\n",
    "            'id': f'i5_migration.stock.location_section_{aisle_number}_{section_number}',\n",
    "            'name': f'Section {section_number}',\n",
    "            'usage': 'internal',\n",
    "            'company_id/id': 'base.main_company',\n",
    "            'location_id/id': f'i5_migration.stock.location_aisle_{aisle_number}',\n",
    "            'temporary_parent_id': 'stock.stock_location_stock'\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    ## Shelf ##\n",
    "    shelf_number = str(location[1].id)[5:7]\n",
    "    shelf_id = f'i5_migration.stock.location_shelf_{aisle_number}_{section_number}_{shelf_number}'\n",
    "    loc_name = str(location[1].description).strip()\n",
    "    if shelf_id not in shelf_ids:\n",
    "        shelf_ids.add(shelf_id)\n",
    "        if not loc_name:\n",
    "            shelf_name = f'Shelf {shelf_number}'\n",
    "        else:\n",
    "            shelf_name = f'Shelf {shelf_number} ({loc_name})'\n",
    "        transformation_result_dataframe = transformation_result_dataframe.append({\n",
    "            'id': shelf_id,\n",
    "            'name': shelf_name,\n",
    "            'usage': 'internal',\n",
    "            'company_id/id': 'base.main_company',\n",
    "            'location_id/id': f'i5_migration.stock.location_section_{aisle_number}_{section_number}',\n",
    "            'temporary_parent_id': 'stock.stock_location_stock',\n",
    "            'location_number': location[1].id\n",
    "        }, ignore_index=True)\n",
    "\n",
    "# Create import file with the locations with temporary parent\n",
    "odoo_locations_temp_parent_dataframe = transformation_result_dataframe.copy(deep=True)\n",
    "odoo_locations_temp_parent_dataframe.drop(columns=['location_id/id'], inplace=True)\n",
    "odoo_locations_temp_parent_dataframe.rename(columns={'temporary_parent_id': 'location_id/id'}, inplace=True)\n",
    "odoo_locations_temp_parent_dataframe.to_csv(f'{GENERATED_CSV_FILES_PATH}i5.locations.temp.parent.csv', index=False)\n",
    "\n",
    "# Create import file with the locations with actual parent\n",
    "odoo_locations_parents_dataframe = transformation_result_dataframe[['id', 'location_id/id']]\n",
    "odoo_locations_parents_dataframe.to_csv(f'{GENERATED_CSV_FILES_PATH}i5.locations.parents.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load i5 locations into Odoo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'stock.location'\n",
    "# Load the i5 locations files with temporary parent\n",
    "import_data(file_csv='i5.locations.temp.parent.csv', model_name=model_name)\n",
    "import_data(file_csv='i5.locations.parents.csv', model_name=model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform Product Categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'product.category'\n",
    "\n",
    "i5_categories_dataframe = pandas.read_csv(f'{INPUT_CSV_FILES_PATH}Group Descriptions.tsv', sep='\\t')\n",
    "\n",
    "i5_categories_dataframe = i5_categories_dataframe.fillna('')\n",
    "col_names = ['GROUP', 'GRDESC', 'STYLE', 'DESC']\n",
    "for col_name in col_names:\n",
    "    i5_categories_dataframe[col_name] = i5_categories_dataframe[col_name].astype(str)\n",
    "    i5_categories_dataframe[col_name] = i5_categories_dataframe[col_name].str.strip()\n",
    "\n",
    "odoo_parents_categories_dataframe= pandas.DataFrame(columns=['id', 'name', 'parent_id/id', 'group'])\n",
    "\n",
    "def build_category_id(category_name):\n",
    "    return f'i5_migration.product.category.{category_name.lower().replace(\" \", \"_\").replace(\"/\", \"_\")}'\n",
    "\n",
    "ids_already_created = set()\n",
    "for row in i5_categories_dataframe.iterrows():\n",
    "    category_name = row[1].GRDESC\n",
    "    category_id = build_category_id(category_name)\n",
    "    parent_category_id = 'product.product_category_all'\n",
    "\n",
    "    if category_id not in ids_already_created:\n",
    "        ids_already_created.add(category_id)\n",
    "        odoo_parents_categories_dataframe = odoo_parents_categories_dataframe.append({\n",
    "            'id': category_id,\n",
    "            'name': category_name,\n",
    "            'parent_id/id': parent_category_id,\n",
    "            'group': row[1].GROUP\n",
    "        }, ignore_index=True)\n",
    "\n",
    "odoo_parents_categories_dataframe.to_csv(f'{GENERATED_CSV_FILES_PATH}i5.categories.parents.csv', index=False)\n",
    "\n",
    "odoo_child_categories_dataframe = pandas.DataFrame(columns=['id', 'name', 'parent_id/id'])\n",
    "\n",
    "def build_child_category_id(category_name, style_code):\n",
    "    return f'i5_migration.product.category.{category_name.lower().replace(\" \", \"_\").replace(\"/\", \"_\")}_child_{style_code.lower()}'\n",
    "\n",
    "for row in i5_categories_dataframe.iterrows():\n",
    "    category_name = row[1].DESC\n",
    "    style_code = row[1].STYLE\n",
    "    category_id = build_child_category_id(row[1].GRDESC, style_code)\n",
    "    parent_id = build_category_id(row[1].GRDESC)\n",
    "    odoo_child_categories_dataframe = odoo_child_categories_dataframe.append({\n",
    "        'id': category_id,\n",
    "        'name': category_name,\n",
    "        'parent_id/id': parent_id,\n",
    "        'group': row[1].GROUP,\n",
    "        'style': style_code,\n",
    "    }, ignore_index=True)\n",
    "\n",
    "odoo_child_categories_dataframe.to_csv(f'{GENERATED_CSV_FILES_PATH}i5.categories.children.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load product.categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'product.category'\n",
    "\n",
    "import_data(file_csv='i5.categories.parents.csv', model_name=model_name, ignore_fields=['group', 'style'])\n",
    "import_data(file_csv='i5.categories.children.csv', model_name=model_name, ignore_fields=['group', 'style'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform Products**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'product.template'\n",
    "\n",
    "categories_dataframe = pandas.read_csv(f'{GENERATED_CSV_FILES_PATH}i5.categories.children.csv')[['id', 'group', 'style']]\n",
    "categories_dataframe.rename(columns={'id': 'categ_id/id'}, inplace=True)\n",
    "col_names = ['categ_id/id', 'group', 'style']\n",
    "for col_name in col_names:\n",
    "    categories_dataframe[col_name] = categories_dataframe[col_name].astype(str)\n",
    "    categories_dataframe[col_name] = categories_dataframe[col_name].str.strip()\n",
    "odoo_products_dataframe = pandas.read_csv(f'{GENERATED_CSV_FILES_PATH}i5.products.csv')\n",
    "\n",
    "i5_products_dataframe = pandas.read_csv(f'{INPUT_CSV_FILES_PATH}MasterProductsList.csv')\n",
    "\n",
    "col_names = ['IMDESC', 'ITMDSC', 'PRICCD', 'IMLIST', 'IMTCST', 'GROUP', 'IMSTYL', 'IMRANK', 'IMGEN', 'IMXRBC', 'vendor_code', 'AMNAME', 'ITEM', 'IMMCST']\n",
    "for col_name in col_names:\n",
    "    i5_products_dataframe[col_name] = i5_products_dataframe[col_name].astype(str)\n",
    "    i5_products_dataframe[col_name] = i5_products_dataframe[col_name].str.strip()\n",
    "\n",
    "def get_purchase_uom(row):\n",
    "    if row.PRICCD == '0':\n",
    "        return 'uom.product_uom_unit'\n",
    "    elif row.PRICCD == '1':\n",
    "        return '__export__.product_uom_21_fd9caca2'\n",
    "    elif row.PRICCD == '2':\n",
    "        return '__export__.product_uom_20_fff5877f'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "odoo_products_dataframe= pandas.DataFrame(columns=['id', 'name', 'default_code', 'barcode', 'list_price', 'standard_price', 'uom_po_id', 'group', 'style'])\n",
    "for row in i5_products_dataframe.itertuples():\n",
    "    prod_name = row.IMDESC\n",
    "    default_code = row.ITEM\n",
    "    odoo_products_dataframe = odoo_products_dataframe.append({\n",
    "      'id': f'i5_migration.product_template_{row.IMGEN}',\n",
    "      'name': row.IMDESC + ' ' + row.ITMDSC,\n",
    "      'default_code': row.IMGEN,\n",
    "      'barcode': row.IMXRBC,\n",
    "      'list_price': row.IMLIST,\n",
    "      'standard_price': row.IMTCST,\n",
    "      'type': 'product',\n",
    "      'uom_po_id/id': get_purchase_uom(row),\n",
    "      'group': row.GROUP,\n",
    "      'style': row.IMSTYL,\n",
    "      'vendor_account_number': row.vendor_code,\n",
    "      'price': row.IMMCST, # Vendors price,\n",
    "      'product_code': row.ITEM,\n",
    "    }, ignore_index=True)\n",
    "\n",
    "odoo_products_dataframe.to_csv(f'{GENERATED_CSV_FILES_PATH}i5.products.csv', index=False)\n",
    "\n",
    "odoo_products_dataframe = odoo_products_dataframe.merge(categories_dataframe, how='left', on=['group', 'style'])\n",
    "# replace NaN values with undefined category\n",
    "odoo_products_dataframe[['categ_id/id']] = odoo_products_dataframe[['categ_id/id']].fillna(value='i5_migration.product.category.national_accounts_child_z7')\n",
    "odoo_products_dataframe.drop(columns=['group', 'style'], inplace=True)\n",
    "odoo_products_dataframe.to_csv(f'{GENERATED_CSV_FILES_PATH}i5.products2.csv', index=False)\n",
    "\n",
    "## Service Items ##\n",
    "i5_service_items_dataframe = pandas.read_csv(f'{INPUT_CSV_FILES_PATH}service_items.tsv', sep='\\t')\n",
    "\n",
    "col_names = ['IMDESC', 'ITMDSC', 'PRICCD', 'IMLIST', 'IMTCST', 'GROUP', 'IMSTYL', 'IMRANK', 'IMGEN', 'IMXRBC', 'AMNAME', 'ITEM', 'IMMCST']\n",
    "for col_name in col_names:\n",
    "    i5_service_items_dataframe[col_name] = i5_service_items_dataframe[col_name].astype(str)\n",
    "    i5_service_items_dataframe[col_name] = i5_service_items_dataframe[col_name].str.strip()\n",
    "i5_service_items_dataframe['GROUP'] = i5_service_items_dataframe['GROUP'].str.replace('.0', '')\n",
    "\n",
    "odoo_service_items_dataframe= pandas.DataFrame(columns=['id', 'name', 'default_code', 'barcode', 'list_price', 'standard_price', 'uom_po_id', 'group', 'style'])\n",
    "for row in i5_service_items_dataframe.itertuples():\n",
    "    prod_name = row.IMDESC\n",
    "    default_code = row.ITEM\n",
    "    odoo_service_items_dataframe = odoo_service_items_dataframe.append({\n",
    "      'id': f'i5_migration.product_template_{row.IMGEN}',\n",
    "      'name': row.IMDESC + ' ' + row.ITMDSC,\n",
    "      'default_code': row.IMGEN,\n",
    "      'barcode': row.IMXRBC,\n",
    "      'list_price': row.IMLIST,\n",
    "      'standard_price': row.IMTCST,\n",
    "      'type': 'service',\n",
    "      'uom_po_id/id': get_purchase_uom(row),\n",
    "      'group': str(int(row.GROUP)) if row.GROUP != 'nan' else '',\n",
    "      'style': row.IMSTYL,\n",
    "      'vendor_name': row.AMNAME,\n",
    "      'price': row.IMMCST, # Vendors price,\n",
    "      'product_code': row.ITEM,\n",
    "    }, ignore_index=True)\n",
    "odoo_service_items_dataframe.to_csv(f'{GENERATED_CSV_FILES_PATH}i5.products.service.items.csv', index=False)\n",
    "\n",
    "odoo_service_items_dataframe = odoo_service_items_dataframe.merge(categories_dataframe, how='left', on=['group', 'style'])\n",
    "# replace NaN values with undefined category\n",
    "odoo_service_items_dataframe[['categ_id/id']] = odoo_service_items_dataframe[['categ_id/id']].fillna(value='i5_migration.product.category.national_accounts_child_z7')\n",
    "odoo_service_items_dataframe.drop(columns=['group', 'style'], inplace=True)\n",
    "\n",
    "\n",
    "vendors_dataframe = pandas.read_csv(f'{GENERATED_CSV_FILES_PATH}i5.vendors.csv')[['id', 'name']]\n",
    "vendors_dataframe.rename(columns={'name': 'vendor_name'}, inplace=True)\n",
    "vendors_dataframe.rename(columns={'id': 'name/id'}, inplace=True)\n",
    "odoo_service_items_dataframe.rename(columns={'AMNAME': 'vendor_name'}, inplace=True)\n",
    "\n",
    "odoo_service_items_suppliers_dataframe = odoo_service_items_dataframe.merge(vendors_dataframe, how='inner', on=['vendor_name'])\n",
    "# merge with vendors to get vendor id\n",
    "odoo_service_items_dataframe = odoo_service_items_dataframe.merge(vendors_dataframe, how='left', on=['vendor_name'])\n",
    "\n",
    "odoo_service_items_dataframe.to_csv(f'{GENERATED_CSV_FILES_PATH}i5.products.template.service.items.csv', index=False)\n",
    "odoo_service_items_suppliers_dataframe.to_csv(f'{GENERATED_CSV_FILES_PATH}i5.products.service.suppliers.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load products**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'product.template'\n",
    "\n",
    "import_data(model_name, file_csv='i5.products2.csv', context={'create_product_product': True, 'tracking_disable': True},\n",
    "            ignore_fields=['vendor_account_number', 'price', 'product_code', 'uom_po_id', 'barcode'])\n",
    "import_data(model_name, file_csv='i5.products.template.service.items.csv', context={'create_product_product': True, 'tracking_disable': True},\n",
    "            ignore_fields=['vendor_name', 'price', 'product_code', 'name/id', 'uom_po_id', 'barcode'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create product.product import file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'product.product'\n",
    "\n",
    "products_dataframe = pandas.read_csv(f'{GENERATED_CSV_FILES_PATH}i5.products2.csv')[['id', 'name', 'default_code']]\n",
    "services_dataframe = pandas.read_csv(f'{GENERATED_CSV_FILES_PATH}i5.products.template.service.items.csv')[['id', 'name', 'default_code']]\n",
    "products_dataframe = pandas.concat([products_dataframe, services_dataframe], ignore_index=True)\n",
    "\n",
    "products_dataframe.rename(columns={'id': 'product_tmpl_id/id'}, inplace=True)\n",
    "products_dataframe[['active']] = True\n",
    "# create the id for the product.product using the default_code\n",
    "products_dataframe['id'] = products_dataframe['default_code'].apply(lambda x: f'i5_migration.product.product_{x}')\n",
    "\n",
    "products_dataframe.drop(columns=['default_code'], inplace=True)\n",
    "\n",
    "products_dataframe.to_csv(f'{GENERATED_CSV_FILES_PATH}i5.product.product.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load product.product**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'product.product'\n",
    "\n",
    "import_data(model_name, file_csv='i5.product.product.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform products' supplier info**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'product.supplierinfo'\n",
    "\n",
    "products_dataframe = pandas.read_csv(f'{GENERATED_CSV_FILES_PATH}i5.products2.csv')\n",
    "products_dataframe = products_dataframe[['id', 'vendor_account_number', 'price', 'product_code', 'uom_po_id/id']]\n",
    "products_dataframe.rename(columns={'id': 'product_tmpl_id/id', 'uom_po_id/id': 'product_uom/id'}, inplace=True)\n",
    "\n",
    "vendors_dataframe = pandas.read_csv(f'{GENERATED_CSV_FILES_PATH}i5.vendors.csv')\n",
    "vendors_dataframe = vendors_dataframe[['id', 'vendor_account_number']]\n",
    "vendors_dataframe.rename(columns={'id': 'name/id'}, inplace=True)\n",
    "\n",
    "odoo_products_suppliers_dataframe = products_dataframe.merge(vendors_dataframe, how='inner', on='vendor_account_number')\n",
    "# Add columns with default values\n",
    "odoo_products_suppliers_dataframe['delay'] = 0\n",
    "odoo_products_suppliers_dataframe['min_qty'] = 1\n",
    "# Generate id for each row with the format i5_migration.product.supplierinfo_{row_index}\n",
    "odoo_products_suppliers_dataframe['id'] = odoo_products_suppliers_dataframe.index.map(lambda x: f'i5_migration.product.supplierinfo_{x}')\n",
    "odoo_products_suppliers_dataframe.drop(columns=['vendor_account_number'], inplace=True)\n",
    "\n",
    "odoo_products_suppliers_dataframe.to_csv(f'{GENERATED_CSV_FILES_PATH}i5.products.suppliers.csv', index=False)\n",
    "\n",
    "## Service items ##\n",
    "services_suppliers_dataframe = pandas.read_csv(f'{GENERATED_CSV_FILES_PATH}i5.products.service.suppliers.csv')\n",
    "services_suppliers_dataframe = services_suppliers_dataframe[['id', 'name/id', 'price', 'product_code', 'uom_po_id/id']]\n",
    "services_suppliers_dataframe.rename(columns={'id': 'product_tmpl_id/id', 'uom_po_id/id': 'product_uom/id'}, inplace=True)\n",
    "services_suppliers_dataframe['id'] = services_suppliers_dataframe.index.map(lambda x: f'i5_migration.product.supplierinfo_service_{x}')\n",
    "services_suppliers_dataframe.to_csv(f'{GENERATED_CSV_FILES_PATH}i5.products.suppliers.services.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load products' supplier info**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'product.supplierinfo'\n",
    "\n",
    "import_data(model_name, 'i5.products.suppliers.csv')\n",
    "import_data(model_name, 'i5.products.suppliers.services.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dca556ecc5dd513367558f6312acb415247f7e6342b10809f71b9a3671f6e71e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
