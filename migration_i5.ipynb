{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hermitage I5 migration notebook\n",
    "\n",
    "This notebook app will run the ETL process to migrate Heremitage's I5 to a new Odoo 15 system.\n",
    "It will read csv/tsv files from the input_csv_files, make the necessary transformations to make it importable in Odoo 15 and then load the data it into Hermitage's new Odoo 15 instance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "- pandas: to make transformations on the data\n",
    "- Models' migration config\n",
    "- Import function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas\n",
    "\n",
    "from models_migration_config import models_migration_config\n",
    "\n",
    "from import_functions import import_data, import_ignored_fields\n",
    "\n",
    "INPUT_CSV_FILES_PATH = 'input_csv_files/'\n",
    "GENERATED_CSV_FILES_PATH = 'generated_csv_files/'\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform Vendors from I5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vendors_file_path = f'{INPUT_CSV_FILES_PATH}APMASTER - Vendors.tsv'\n",
    "vendors_dataframe = pandas.read_csv(vendors_file_path, sep='\\t')\n",
    "vendors_dataframe = vendors_dataframe.fillna('')\n",
    "# AMVEND\tAMNAME\tAMADR1\tAMADR2\tAMADR3\tAMTELE\tAMFRGT\tactual_term\n",
    "# 1\tBROAN MFG OR EDN\t4641 PAYSPHERE CIRCLE\tCHICAGO,IL 60674         \t\t8778470145\t1250\t2% 10TH PROX\n",
    "# 172\tHUNTER FAN COMPANY\tP O BOX 19773\t\tPALATINE IL 60055-9773\t9017441200\t1000\t1% 20TH\n",
    "# 10003\tLEDVANCE OR IMARK\tP O BOX 72524\t(OSRAM)\tCLEVELAND OH 44192\t8002555042\t1000\t2% 90Days\n",
    "# 10004\tADVANCE TRANSFORMER CO\tP O BOX 100332\tATLANTA GA  30384\t\t0\t750\t2% 10TH PROX\n",
    "# 10005\tLUTRON ELECTRONICS CO INC\tP O BOX 644396\t\tPITTSBURGH, PA 15264-4396\t8005239466\t500\t1%10TH PROX\n",
    "\n",
    "col_names = ['AMVEND', 'AMNAME', 'AMADR1', 'AMADR2', 'AMADR3', 'AMTELE', 'AMFRGT', 'actual_term']\n",
    "for col_name in col_names:\n",
    "    vendors_dataframe[col_name] = vendors_dataframe[col_name].astype(str)\n",
    "    vendors_dataframe[col_name] = vendors_dataframe[col_name].str.strip()\n",
    "\n",
    "# Move AMADR1 column to the end for better visibility\n",
    "vendors_dataframe = vendors_dataframe[['AMVEND', 'AMNAME', 'AMADR2', 'AMADR3', 'AMTELE', 'AMFRGT', 'actual_term', 'AMADR1']]\n",
    "vendors_dataframe.rename(columns={'AMADR1': 'street'}, inplace=True)\n",
    "\n",
    "vendors_dataframe['street2'] = ''\n",
    "vendors_dataframe['city'] = ''\n",
    "vendors_dataframe['state_code'] = ''\n",
    "vendors_dataframe['zip'] = ''\n",
    "\n",
    "def is_zip(zip_code : str) -> bool:\n",
    "    \"\"\"\n",
    "    >>> is_zip('6067')\n",
    "    True\n",
    "    >>> is_zip('60674')\n",
    "    True\n",
    "    >>> is_zip('60674-1234')\n",
    "    True\n",
    "    \"\"\"\n",
    "    return bool(re.match(r'^\\d{5}(-\\d{4})?$', zip_code)) or bool(re.match(r'^\\d{4}', zip_code))\n",
    "\n",
    "us_states = {\n",
    "    'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY',\n",
    "    'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY',\n",
    "    'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY'\n",
    "}\n",
    "\n",
    "def is_a_state(state : str) -> bool:\n",
    "    return state in us_states\n",
    "\n",
    "def clean_address_field(address_field: str) -> str:\n",
    "    address_field = address_field.strip()\n",
    "    address_field = re.sub(r'\\s+', ' ', address_field)\n",
    "    address_field = address_field.replace(',', ' ')\n",
    "    return address_field\n",
    "\n",
    "\n",
    "for row_index, row in vendors_dataframe.iterrows():\n",
    "    row_address2 = row.AMADR2 or ''\n",
    "    row_address2 = clean_address_field(row_address2)\n",
    "    row_address3 = row.AMADR3 or ''\n",
    "    row_address3 = clean_address_field(row_address3)\n",
    "\n",
    "    if row_address3:\n",
    "        row.street2 = row_address2\n",
    "        city_state_zip = row_address3\n",
    "    else:\n",
    "        city_state_zip = row_address2\n",
    "    if city_state_zip:\n",
    "        city_state_zip_splitted = city_state_zip.split(' ')[::-1]\n",
    "\n",
    "        for i, address_field in enumerate(city_state_zip_splitted):\n",
    "            if is_zip(address_field):\n",
    "                row.zip = address_field.strip()\n",
    "            elif is_a_state(address_field):\n",
    "                row.state_code = address_field.strip()\n",
    "            else:\n",
    "                row.city = ' '.join(city_state_zip_splitted[i:][::-1]).strip()\n",
    "                break\n",
    "        if not row.zip or not row.state_code or not row.city and row.street2:\n",
    "            city_state_zip_splitted = row.street2.split(' ')[::-1]\n",
    "            for i, address_field in enumerate(city_state_zip_splitted):\n",
    "                if not row.zip and is_zip(address_field):\n",
    "                    row.zip = address_field.strip()\n",
    "                elif not row.state_code and is_a_state(address_field):\n",
    "                    row.state_code = address_field.strip()\n",
    "                elif not row.city:\n",
    "                    row.city = ' '.join(city_state_zip_splitted[i:][::-1]).strip()\n",
    "                    break\n",
    "\n",
    "states_dataframe = pandas.read_csv(f'{INPUT_CSV_FILES_PATH}state_codes.csv')\n",
    "# Merge with states to get the state and country external id\n",
    "vendors_dataframe = pandas.merge(vendors_dataframe, states_dataframe, on='state_code', how='left')\n",
    "\n",
    "# Merge with the payment terms to get the payment term external id\n",
    "payment_terms_dataframe = pandas.read_csv(f'{INPUT_CSV_FILES_PATH}account.payment.term.csv')\n",
    "payment_terms_dataframe.rename(columns={'name': 'actual_term', 'id': 'property_supplier_payment_term_id/id'}, inplace=True)\n",
    "merge_payment_terms_dataframe = payment_terms_dataframe[['actual_term', 'property_supplier_payment_term_id/id']]\n",
    "\n",
    "vendors_dataframe = pandas.merge(vendors_dataframe, merge_payment_terms_dataframe, on='actual_term', how='left')\n",
    "# remove unneeded columns\n",
    "vendors_dataframe.drop(columns=['AMADR2', 'AMADR3', 'AMFRGT', 'actual_term', 'state_code'], inplace=True)\n",
    "# rename columns to match the odoo model\n",
    "vendors_dataframe.rename(columns={\n",
    "    'AMVEND': 'vendor_account_number',\n",
    "    'AMNAME': 'name',\n",
    "    'AMTELE': 'phone'\n",
    "}, inplace=True)\n",
    "\n",
    "vendors_dataframe.insert(0, 'supplier_rank', 1)\n",
    "# add Vendor tag\n",
    "vendors_dataframe.insert(0, 'category_id/id', '__export__.res_partner_category_56_7fafda33')\n",
    "# add id column populated with ids generated from 'i5_migration.res.partner.vendors_{row_index}'\n",
    "vendors_dataframe.insert(0, 'id', [f'i5_migration.res.partner.vendor_{row_index}' for row_index in range(1, 1 + len(vendors_dataframe))])\n",
    "\n",
    "vendors_dataframe.to_csv(f'{GENERATED_CSV_FILES_PATH}i5.vendors.csv', index=False, sep=',')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load vendors (res.partner)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_data(file_csv='i5.vendors.csv', model_name='res.partner')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform locations from I5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = 'stock.location'\n",
    "\n",
    "company_id = 'base.main_company'\n",
    "\n",
    "locations_dataframe = pandas.read_csv(f'{INPUT_CSV_FILES_PATH}RFLOCATE.tsv', sep='\\t')\n",
    "# locations_dataframe = locations_dataframe.fillna('')\n",
    "# #cast all columns to str\n",
    "# locations_dataframe = locations_dataframe.astype(str)\n",
    "# #Trimm spaces\n",
    "# locations_dataframe = locations_dataframe.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "#Format of i5 locations file\n",
    "# id  name\n",
    "# 9010101\tINVENTORY LOCATION  \n",
    "# 9060101\t                    \n",
    "# 9200101\tCOMM WHSE           \n",
    "# 9270101\t                    \n",
    "# 9270201\t                    \n",
    "# 9270301\t                    \n",
    "# 9270401\t                    \n",
    "# 9270501\t                    \n",
    "# 9270601\t                    \n",
    "# 9270701\t                    \n",
    "\n",
    "# Main stock.location id: stock.stock_location_stock\n",
    "\n",
    "# Columns needed for Odoo's locations dataframe\n",
    "# id,name,usage,company_id/id,parent_id/id,temporary_parent_id\n",
    "\n",
    "# The locations hierarchy is as follows:\n",
    "# 1 - stock.stock_location_stock --> i5 Value: 9\n",
    "# 2 - Aisle\n",
    "# 3 - Section(venv) fernando@fernando-Z370-AORUS-Ultra-Gaming:/media/fernando/Shared/hermitage$ \n",
    "# 4 - INVENTORY LOCATION (if it has a name the shelf location is called by the name, otherwise it is called by the id)\n",
    "# Would generate the following locations:\n",
    "# i5_migration.stock.location_aisle_01,Aisle 01,internal,base.main_company,stock.stock_location_stock,stock.stock_location_stock\n",
    "# i5_migration.stock.location_section_01_01,Section 01,internal,base.main_company,i5_migration.stock.location_aisle_01,stock.stock_location_stock\n",
    "# i5_migration.stock.location_shelf_01_01_01,Shelf 01 (INVENTORY LOCATION),internal,base.main_company,i5_migration.stock.location_section_01_01,stock.stock_location_stock\n",
    "\n",
    "# Example 2: for location 9060101\n",
    "# 1 - stock.stock_location_stock (already created)\n",
    "# 2 - Aisle 06\n",
    "# 3 - Section 01\n",
    "# 4 - Shelf 01\n",
    "# Would generate the following locations:\n",
    "# i5_migration.stock.location_aisle_06,Aisle 06,internal,base.main_company,stock.stock_location_stock,stock.stock_location_stock\n",
    "# i5_migration.stock.location_section_06_01,Section 01,internal,base.main_company,i5_migration.stock.location_aisle_06,stock.stock_location_stock\n",
    "# i5_migration.stock.location_shelf_06_01_01,Shelf 01,internal,base.main_company,i5_migration.stock.location_section_06_01,stock.stock_location_stock\n",
    "\n",
    "\n",
    "transformation_result_dataframe = pandas.DataFrame(columns=['id', 'name', 'usage', 'company_id/id', 'location_id/id', 'temporary_parent_id'])\n",
    "aisles_ids = set()\n",
    "section_ids = set()\n",
    "shelf_ids = set()\n",
    "for location in locations_dataframe.iterrows():\n",
    "    ## Aisle ##\n",
    "    aisle_number = str(location[1].id)[1:3]\n",
    "    aisle_id = f'i5_migration.stock.location_aisle_{aisle_number}'\n",
    "    if aisle_id not in aisles_ids:\n",
    "        aisles_ids.add(aisle_id)\n",
    "        transformation_result_dataframe = transformation_result_dataframe.append({\n",
    "            'id': f'i5_migration.stock.location_aisle_{aisle_number}',\n",
    "            'name': f'Aisle {aisle_number}',\n",
    "            'usage': 'internal',\n",
    "            'company_id/id': 'base.main_company',\n",
    "            'location_id/id': 'stock.stock_location_stock',\n",
    "            'temporary_parent_id': 'stock.stock_location_stock'\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    ## Section ##\n",
    "    section_number = str(location[1].id)[3:5]\n",
    "    section_id = f'i5_migration.stock.location_section_{aisle_number}_{section_number}'\n",
    "    if section_id not in section_ids:\n",
    "        section_ids.add(section_id)\n",
    "        transformation_result_dataframe = transformation_result_dataframe.append({\n",
    "            'id': f'i5_migration.stock.location_section_{aisle_number}_{section_number}',\n",
    "            'name': f'Section {section_number}',\n",
    "            'usage': 'internal',\n",
    "            'company_id/id': 'base.main_company',\n",
    "            'location_id/id': f'i5_migration.stock.location_aisle_{aisle_number}',\n",
    "            'temporary_parent_id': 'stock.stock_location_stock'\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    ## Shelf ##\n",
    "    shelf_number = str(location[1].id)[5:7]\n",
    "    shelf_id = f'i5_migration.stock.location_shelf_{aisle_number}_{section_number}_{shelf_number}'\n",
    "    loc_name = str(location[1].description).strip()\n",
    "    if shelf_id not in shelf_ids:\n",
    "        shelf_ids.add(shelf_id)\n",
    "        if not loc_name:\n",
    "            shelf_name = f'Shelf {shelf_number}'\n",
    "        else:\n",
    "            shelf_name = f'Shelf {shelf_number} ({loc_name})'\n",
    "        transformation_result_dataframe = transformation_result_dataframe.append({\n",
    "            'id': shelf_id,\n",
    "            'name': shelf_name,\n",
    "            'usage': 'internal',\n",
    "            'company_id/id': 'base.main_company',\n",
    "            'location_id/id': f'i5_migration.stock.location_section_{aisle_number}_{section_number}',\n",
    "            'temporary_parent_id': 'stock.stock_location_stock'\n",
    "        }, ignore_index=True)\n",
    "\n",
    "# Create import file with the locations with temporary parent\n",
    "odoo_locations_temp_parent_dataframe = transformation_result_dataframe.copy(deep=True)\n",
    "odoo_locations_temp_parent_dataframe.drop(columns=['location_id/id'], inplace=True)\n",
    "odoo_locations_temp_parent_dataframe.rename(columns={'temporary_parent_id': 'location_id/id'}, inplace=True)\n",
    "odoo_locations_temp_parent_dataframe.to_csv(f'{GENERATED_CSV_FILES_PATH}i5.locations.temp.parent.csv', index=False)\n",
    "\n",
    "# Create import file with the locations with actual parent\n",
    "odoo_locations_parents_dataframe = transformation_result_dataframe[['id', 'location_id/id']]\n",
    "odoo_locations_parents_dataframe.to_csv(f'{GENERATED_CSV_FILES_PATH}i5.locations.parents.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load i5 locations into Odoo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'stock.location'\n",
    "# Load the i5 locations files with temporary parent\n",
    "import_data(file_csv='i5.locations.temp.parent.csv', model_name=model_name)\n",
    "import_data(file_csv='i5.locations.parents.csv', model_name=model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
